{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity Check For Click-based Lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.system(\"export LC_ALL=en_US.UTF-8\")\n",
    "os.system(\"export LANG=en_US.UTF-8\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2, linewidth=np.inf, suppress=True)\n",
    "np.seterr(invalid='ignore', divide='ignore')\n",
    "\n",
    "import cPickle as pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import hsv_to_rgb\n",
    "\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "from ipywidgets import interact, interactive, Dropdown, FloatText, VBox, HBox\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# Load the click models for the queries of interest.\n",
    "# with open('./data/model_query_uniform_lambdas_v1_collection_c2.pkl') as ifile:\n",
    "# with open('./data/model_query_softmax_lambdas_v1_collection_c2.pkl') as ifile:\n",
    "# with open('./data/model_query_uniform_lambdas_v2_collection_c2.pkl') as ifile:\n",
    "with open('./data/model_query_softmax_lambdas_v2_collection_c2.pkl') as ifile:\n",
    "# with open('./data/model_query_uniform_lambdas_v3_collection_c2.pkl') as ifile:\n",
    "# with open('./data/model_query_softmax_lambdas_v3_collection_c2.pkl') as ifile:\n",
    "    MQD = pickle.load(ifile)\n",
    "\n",
    "# For reproducibility -- re-seed the click models' RNGs.\n",
    "for click_model_type in MQD:\n",
    "    for query in MQD[click_model_type]:\n",
    "        MQD[click_model_type][query]['model'].seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Available Click Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MQD.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSE Error In Delta Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "query_model_losses = {}\n",
    "for query in MQD['CM']:\n",
    "    model_losses = {}\n",
    "    for click_model_name in MQD:\n",
    "        model = MQD[click_model_name][query]['model']\n",
    "        relevances = MQD[click_model_name][query]['relevances']\n",
    "        n_documents = len(relevances)\n",
    "\n",
    "        test_lambdas = np.zeros((n_documents, n_documents), dtype='float64')\n",
    "\n",
    "        if click_model_name == 'CM':\n",
    "            p_attract = model.click_proba\n",
    "\n",
    "            for i in range(n_documents):\n",
    "                for j in range(n_documents):\n",
    "                    if i == j: continue\n",
    "                    test_lambdas[i, j] = (1.0 - p_attract[j]) * p_attract[i]\n",
    "\n",
    "        elif click_model_name == 'PBM':\n",
    "            p_attract = model.click_proba\n",
    "            p_exam = model.exam_proba\n",
    "\n",
    "            for i in range(n_documents):\n",
    "                for j in range(n_documents):\n",
    "                    if i == j: continue\n",
    "                    test_lambdas[i, j] = (1.0 - p_exam[0] * p_attract[j]) * p_exam[1] * p_attract[i]\n",
    "\n",
    "        elif click_model_name == 'CCM':\n",
    "            p_attract = model.p_attraction\n",
    "            tau1 = 1.0 - model.p_stop_noclick\n",
    "            tau2 = 1.0 - model.p_stop_click_norel\n",
    "            tau3 = 1.0 - model.p_stop_click_rel\n",
    "\n",
    "            for i in range(n_documents):\n",
    "                for j in range(n_documents):\n",
    "                    if i == j: continue\n",
    "                    test_lambdas[i, j] = (1.0 - p_attract[j]) * tau1 * p_attract[i]\n",
    "\n",
    "        elif click_model_name == 'DBN':\n",
    "            p_attract = model.click_proba\n",
    "            p_cont = 1.0 - model.stop_proba\n",
    "            p_abandon = model.abandon_proba\n",
    "\n",
    "            for i in range(n_documents):\n",
    "                for j in range(n_documents):\n",
    "                    if i == j: continue\n",
    "                    test_lambdas[i, j] = (1.0 - p_attract[j]) * p_attract[i]\n",
    "\n",
    "        elif click_model_name == 'DCM':\n",
    "            p_attraction = model.click_proba\n",
    "            p_cont = 1.0 - model.stop_proba\n",
    "\n",
    "            for i in range(n_documents):\n",
    "                for j in range(n_documents):\n",
    "                    if i == j: continue\n",
    "                    test_lambdas[i, j] = (1.0 - p_attraction[j]) * p_attraction[i]\n",
    "\n",
    "        elif click_model_name == 'UBM':\n",
    "            p_attraction = model.p_attraction\n",
    "            p_examination = model.p_examination\n",
    "\n",
    "            for i in range(n_documents):\n",
    "                for j in range(n_documents):\n",
    "                    if i == j: continue\n",
    "                    test_lambdas[i, j] = (1.0 - p_attraction[j]) * p_examination[1, -1] * p_attraction[i]\n",
    "\n",
    "        else:\n",
    "            raise ValueError('unknow click model: %s' % click_model_name)\n",
    "\n",
    "        # This is what we want to estimate with click lambdas?\n",
    "        test_lambdas = test_lambdas - test_lambdas.T\n",
    "\n",
    "        viewed_loss, total_loss = np.empty(10), np.empty(10)\n",
    "        for i in range(10):\n",
    "            viewed_lambdas = MQD[click_model_name][query]['stats'][1000000]['viewed_lambdas'][i]\n",
    "            total_lambdas = MQD[click_model_name][query]['stats'][1000000]['total_lambdas'][i]\n",
    "\n",
    "            viewed_loss[i] = np.mean((test_lambdas - viewed_lambdas)**2)\n",
    "            total_loss[i] = np.mean((test_lambdas - total_lambdas)**2)\n",
    "        \n",
    "        model_losses[click_model_name] = (np.mean(viewed_loss), np.std(viewed_loss),\n",
    "                                          np.mean(total_loss), np.std(total_loss))\n",
    "    query_model_losses[query] = model_losses\n",
    "\n",
    "print '   QUERY     MODEL     VL/MSE       VL/STD       TL/MSE       TL/STD'\n",
    "print '  -------   -------   --------     --------     --------     --------'\n",
    "for click_model_name in query_model_losses['2548']:\n",
    "    for query in query_model_losses:\n",
    "        params = (query, click_model_name) + query_model_losses[query][click_model_name]\n",
    "        print '{0:>8s} {1:>8s} {2:>12.6f} {3:>12.6f} {4:>12.6f} {5:>12.6f}'.format(*params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Click Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "click_model_name = 'UBM'\n",
    "\n",
    "printed_model_characteristics = False\n",
    "\n",
    "for query in MQD[click_model_name]:\n",
    "    model = MQD[click_model_name][query]['model']\n",
    "    relevances = MQD[click_model_name][query]['relevances']\n",
    "    n_documents = len(relevances)\n",
    "    \n",
    "    deltas = relevances[:, None] - relevances[None, :]\n",
    "    test_lambdas = np.zeros((n_documents, n_documents), dtype='float64')\n",
    "\n",
    "    if click_model_name == 'CM':\n",
    "        p_attract = model.click_proba    \n",
    "        \n",
    "        if not printed_model_characteristics:\n",
    "            printed_model_characteristics = True\n",
    "            \n",
    "            print 'CM model'\n",
    "            print '--------'\n",
    "            print 'Attractiveness:', p_attract\n",
    "            print\n",
    "            \n",
    "        for i in range(n_documents):\n",
    "            for j in range(n_documents):\n",
    "                if i == j: continue\n",
    "                test_lambdas[i, j] = (1.0 - p_attract[j]) * p_attract[i]\n",
    "\n",
    "    elif click_model_name == 'PBM':\n",
    "        p_attract = model.click_proba\n",
    "        p_exam = model.exam_proba\n",
    "        \n",
    "        if not printed_model_characteristics:\n",
    "            printed_model_characteristics = True\n",
    "            \n",
    "            print 'PBM model'\n",
    "            print '---------'\n",
    "            print 'Attractiveness:', p_attract\n",
    "            print 'Examination:   ', p_exam\n",
    "            print\n",
    "\n",
    "        for i in range(n_documents):\n",
    "            for j in range(n_documents):\n",
    "                if i == j: continue\n",
    "                test_lambdas[i, j] = (1.0 - p_exam[0] * p_attract[j]) * p_exam[1] * p_attract[i]\n",
    "\n",
    "    elif click_model_name == 'CCM':\n",
    "        p_attract = model.p_attraction\n",
    "        tau1 = 1.0 - model.p_stop_noclick\n",
    "        tau2 = 1.0 - model.p_stop_click_norel\n",
    "        tau3 = 1.0 - model.p_stop_click_rel\n",
    "        \n",
    "        if not printed_model_characteristics:\n",
    "            printed_model_characteristics = True\n",
    "            \n",
    "            print 'PBM model'\n",
    "            print '---------'\n",
    "            print 'Attractiveness:', p_attract\n",
    "            print 'Tau1:          ', tau1\n",
    "            print 'Tau2:          ', tau2\n",
    "            print 'Tau3:          ', tau3\n",
    "            print\n",
    "\n",
    "        for i in range(n_documents):\n",
    "            for j in range(n_documents):\n",
    "                if i == j: continue\n",
    "                test_lambdas[i, j] = (1.0 - p_attract[j]) * tau1 * p_attract[i]\n",
    "\n",
    "    elif click_model_name == 'DBN':\n",
    "        p_attract = model.click_proba\n",
    "        p_cont = 1.0 - model.stop_proba\n",
    "        p_abandon = model.abandon_proba\n",
    "        \n",
    "        if not printed_model_characteristics:\n",
    "            printed_model_characteristics = True\n",
    "            \n",
    "            print 'DBN model'\n",
    "            print '---------'\n",
    "            print 'Attractiveness:', p_attract\n",
    "            print 'Continuation:  ', p_cont\n",
    "            print 'Abandonment:   ', p_abandon\n",
    "\n",
    "        for i in range(n_documents):\n",
    "            for j in range(n_documents):\n",
    "                if i == j: continue\n",
    "                test_lambdas[i, j] = (1.0 - p_attract[j]) * p_attract[i]\n",
    "\n",
    "    elif click_model_name == 'DCM':\n",
    "        p_attraction = model.click_proba\n",
    "        p_cont = 1.0 - model.stop_proba\n",
    "        \n",
    "        if not printed_model_characteristics:\n",
    "            printed_model_characteristics = True\n",
    "            \n",
    "            print 'DCM model'\n",
    "            print '---------'\n",
    "            print 'Attractiveness:', p_attraction\n",
    "            print 'Continuation:  ', p_cont\n",
    "            print\n",
    "\n",
    "        for i in range(n_documents):\n",
    "            for j in range(n_documents):\n",
    "                if i == j: continue\n",
    "                test_lambdas[i, j] = (1.0 - p_attraction[j]) * p_attraction[i]\n",
    "        \n",
    "    elif click_model_name == 'UBM':\n",
    "        p_attraction = model.p_attraction\n",
    "        p_examination = model.p_examination\n",
    "        \n",
    "        if not printed_model_characteristics:\n",
    "            printed_model_characteristics = True\n",
    "            \n",
    "            print 'UBM model'\n",
    "            print '---------'\n",
    "            print 'Attractiveness:', p_attraction\n",
    "            print 'Examination:  '\n",
    "            print p_examination[:,[9] + range(9)].T\n",
    "            print\n",
    "\n",
    "        for i in range(n_documents):\n",
    "            for j in range(n_documents):\n",
    "                if i == j: continue\n",
    "                test_lambdas[i, j] = (1.0 - p_attraction[j]) * p_examination[1, -1] * p_attraction[i]\n",
    "\n",
    "    else:\n",
    "        raise ValueError('unknow click model: %s' % click_model_name)\n",
    "\n",
    "    # This is what we want to estimate with click lambdas?\n",
    "    test_lambdas = test_lambdas - test_lambdas.T\n",
    "\n",
    "    viewed_loss, total_loss = np.empty(10), np.empty(10)\n",
    "    for i in range(10):\n",
    "        viewed_lambdas = MQD[click_model_name][query]['stats'][1000000]['viewed_lambdas'][i]\n",
    "        total_lambdas = MQD[click_model_name][query]['stats'][1000000]['total_lambdas'][i]\n",
    "    \n",
    "        viewed_loss[i] = np.mean((test_lambdas - viewed_lambdas)**2)\n",
    "        total_loss[i] = np.mean((test_lambdas - total_lambdas)**2)        \n",
    "    \n",
    "    lambdas = MQD[click_model_name][query]['stats'][1000000]['lambdas'][0]\n",
    "    \n",
    "    viewed_lambdas = MQD[click_model_name][query]['stats'][1000000]['viewed_lambdas'][0]\n",
    "    viewed_counts = MQD[click_model_name][query]['stats'][1000000]['viewed_counts'][0]\n",
    "    \n",
    "    total_lambdas = MQD[click_model_name][query]['stats'][1000000]['total_lambdas'][0]\n",
    "    total_counts = MQD[click_model_name][query]['stats'][1000000]['total_counts'][0]\n",
    "    \n",
    "    print 'deltas:'\n",
    "    print '-------'\n",
    "    print deltas\n",
    "    print\n",
    "    print 'test lambdas:'\n",
    "    print '-------------'\n",
    "    print test_lambdas\n",
    "    print \n",
    "    print 'viewed lambdas'\n",
    "    print '--------------'\n",
    "    print 'MSE: %.6f (+/- %.6f SE)' % (np.mean(viewed_loss), np.std(viewed_loss))\n",
    "    print viewed_lambdas\n",
    "    print\n",
    "    print 'total lambdas'\n",
    "    print '--------------'\n",
    "    print 'MSE: %.6f (+/- %.6f SE)' % (np.mean(total_loss), np.std(total_loss))\n",
    "    print total_lambdas\n",
    "    print\n",
    "    print 'test lambdas / deltas:'\n",
    "    print '----------------------'\n",
    "    print np.nan_to_num(test_lambdas / deltas)\n",
    "    print\n",
    "    print 'viewed lambdas / deltas:'\n",
    "    print '----------------------'\n",
    "    print np.nan_to_num(viewed_lambdas / deltas)\n",
    "    print\n",
    "    print 'total lambdas / deltas:'\n",
    "    print '----------------------'\n",
    "    print np.nan_to_num(total_lambdas / deltas)\n",
    "    print\n",
    "    print 'lambdas:'\n",
    "    print lambdas\n",
    "    print\n",
    "    print 'total counts:'\n",
    "    print '-------------'\n",
    "    print total_counts\n",
    "    print\n",
    "    print 'viewed counts:'\n",
    "    print '--------------'\n",
    "    print viewed_counts\n",
    "    print\n",
    "    print 'viewed / total counts:'\n",
    "    print '----------------------'\n",
    "    print np.nan_to_num(1.0 * viewed_counts / total_counts)\n",
    "    break\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilities of Ranking-Click Patterns for UBM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Code Generating Ranking-Click Paterns and Their Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import permutations\n",
    "\n",
    "def generate_clicks(n):\n",
    "    i = 0\n",
    "    while i < (1 << n):\n",
    "        cs = []\n",
    "        for j in range(n):\n",
    "            cs.append(1 if (i & (1 << (n - 1 - j))) > 0 else 0)\n",
    "        yield cs\n",
    "        i += 1\n",
    "\n",
    "def generate_latex_table_header():\n",
    "    return r'\\begin{array}{|c|c|l|}' + '\\n' + r'\\hline\\hline'\n",
    "\n",
    "def generate_latex_table_body(ranking, clicks):\n",
    "    last_c_r = 0\n",
    "\n",
    "    if ranking.index('y') < ranking.index('x'):\n",
    "        return None\n",
    "\n",
    "    result = ''.join(ranking) + ' & ' + ''.join(map(str, clicks)) + ' & '\n",
    "\n",
    "    for r, c_r in enumerate(clicks):\n",
    "        if c_r == 1:\n",
    "            result += r'\\gamma_{%d,%d}\\alpha_{%c}' % (last_c_r, r + 1, ranking[r])\n",
    "            last_c_r = r + 1\n",
    "        else:\n",
    "            result += r'(1 - \\gamma_{%d,%d}\\alpha_{%c})' % (last_c_r, r + 1, ranking[r])\n",
    "        if r + 1 < len(clicks):\n",
    "            result += r' \\cdot '\n",
    "    result += r'\\\\'\n",
    "    return result\n",
    "\n",
    "def generate_latex_table_footer():\n",
    "    return r'\\hline\\hline' + '\\n' + r'\\end{array}'\n",
    "\n",
    "rankings = list(permutations('xyz'))\n",
    "clicks = list(generate_clicks(3))\n",
    "\n",
    "print generate_latex_table_header()\n",
    "\n",
    "for i, r in enumerate(rankings):\n",
    "    for c in clicks:\n",
    "        s = generate_latex_table_body(r, c)\n",
    "        if s is not None:\n",
    "            print s\n",
    "    if s is not None and i + 1 < len(rankings):\n",
    "        print '\\hline'\n",
    "\n",
    "print generate_latex_table_footer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{|c|c|l|}\n",
    "\\hline\\hline\n",
    "xyz & 000 & (1 - \\gamma_{0,1}\\alpha_{x}) \\cdot (1 - \\gamma_{0,2}\\alpha_{y}) \\cdot (1 - \\gamma_{0,3}\\alpha_{z})\\\\\n",
    "xyz & 001 & (1 - \\gamma_{0,1}\\alpha_{x}) \\cdot (1 - \\gamma_{0,2}\\alpha_{y}) \\cdot \\gamma_{0,3}\\alpha_{z}\\\\\n",
    "xyz & 010 & (1 - \\gamma_{0,1}\\alpha_{x}) \\cdot \\gamma_{0,2}\\alpha_{y} \\cdot (1 - \\gamma_{2,3}\\alpha_{z})\\\\\n",
    "xyz & 011 & (1 - \\gamma_{0,1}\\alpha_{x}) \\cdot \\gamma_{0,2}\\alpha_{y} \\cdot \\gamma_{2,3}\\alpha_{z}\\\\\n",
    "xyz & 100 & \\gamma_{0,1}\\alpha_{x} \\cdot (1 - \\gamma_{1,2}\\alpha_{y}) \\cdot (1 - \\gamma_{1,3}\\alpha_{z})\\\\\n",
    "xyz & 101 & \\gamma_{0,1}\\alpha_{x} \\cdot (1 - \\gamma_{1,2}\\alpha_{y}) \\cdot \\gamma_{1,3}\\alpha_{z}\\\\\n",
    "xyz & 110 & \\gamma_{0,1}\\alpha_{x} \\cdot \\gamma_{1,2}\\alpha_{y} \\cdot (1 - \\gamma_{2,3}\\alpha_{z})\\\\\n",
    "xyz & 111 & \\gamma_{0,1}\\alpha_{x} \\cdot \\gamma_{1,2}\\alpha_{y} \\cdot \\gamma_{2,3}\\alpha_{z}\\\\\n",
    "\\hline\n",
    "xzy & 000 & (1 - \\gamma_{0,1}\\alpha_{x}) \\cdot (1 - \\gamma_{0,2}\\alpha_{z}) \\cdot (1 - \\gamma_{0,3}\\alpha_{y})\\\\\n",
    "xzy & 001 & (1 - \\gamma_{0,1}\\alpha_{x}) \\cdot (1 - \\gamma_{0,2}\\alpha_{z}) \\cdot \\gamma_{0,3}\\alpha_{y}\\\\\n",
    "xzy & 010 & (1 - \\gamma_{0,1}\\alpha_{x}) \\cdot \\gamma_{0,2}\\alpha_{z} \\cdot (1 - \\gamma_{2,3}\\alpha_{y})\\\\\n",
    "xzy & 011 & (1 - \\gamma_{0,1}\\alpha_{x}) \\cdot \\gamma_{0,2}\\alpha_{z} \\cdot \\gamma_{2,3}\\alpha_{y}\\\\\n",
    "xzy & 100 & \\gamma_{0,1}\\alpha_{x} \\cdot (1 - \\gamma_{1,2}\\alpha_{z}) \\cdot (1 - \\gamma_{1,3}\\alpha_{y})\\\\\n",
    "xzy & 101 & \\gamma_{0,1}\\alpha_{x} \\cdot (1 - \\gamma_{1,2}\\alpha_{z}) \\cdot \\gamma_{1,3}\\alpha_{y}\\\\\n",
    "xzy & 110 & \\gamma_{0,1}\\alpha_{x} \\cdot \\gamma_{1,2}\\alpha_{z} \\cdot (1 - \\gamma_{2,3}\\alpha_{y})\\\\\n",
    "xzy & 111 & \\gamma_{0,1}\\alpha_{x} \\cdot \\gamma_{1,2}\\alpha_{z} \\cdot \\gamma_{2,3}\\alpha_{y}\\\\\n",
    "\\hline\n",
    "zxy & 000 & (1 - \\gamma_{0,1}\\alpha_{z}) \\cdot (1 - \\gamma_{0,2}\\alpha_{x}) \\cdot (1 - \\gamma_{0,3}\\alpha_{y})\\\\\n",
    "zxy & 001 & (1 - \\gamma_{0,1}\\alpha_{z}) \\cdot (1 - \\gamma_{0,2}\\alpha_{x}) \\cdot \\gamma_{0,3}\\alpha_{y}\\\\\n",
    "zxy & 010 & (1 - \\gamma_{0,1}\\alpha_{z}) \\cdot \\gamma_{0,2}\\alpha_{x} \\cdot (1 - \\gamma_{2,3}\\alpha_{y})\\\\\n",
    "zxy & 011 & (1 - \\gamma_{0,1}\\alpha_{z}) \\cdot \\gamma_{0,2}\\alpha_{x} \\cdot \\gamma_{2,3}\\alpha_{y}\\\\\n",
    "zxy & 100 & \\gamma_{0,1}\\alpha_{z} \\cdot (1 - \\gamma_{1,2}\\alpha_{x}) \\cdot (1 - \\gamma_{1,3}\\alpha_{y})\\\\\n",
    "zxy & 101 & \\gamma_{0,1}\\alpha_{z} \\cdot (1 - \\gamma_{1,2}\\alpha_{x}) \\cdot \\gamma_{1,3}\\alpha_{y}\\\\\n",
    "zxy & 110 & \\gamma_{0,1}\\alpha_{z} \\cdot \\gamma_{1,2}\\alpha_{x} \\cdot (1 - \\gamma_{2,3}\\alpha_{y})\\\\\n",
    "zxy & 111 & \\gamma_{0,1}\\alpha_{z} \\cdot \\gamma_{1,2}\\alpha_{x} \\cdot \\gamma_{2,3}\\alpha_{y}\\\\\n",
    "\\hline\\hline\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X skipped and Y clicked\n",
    "Binary random variable $\\lambda_{y,x}$ is 1 only if the document $x$ was presented above document $y$ and the user clicked on document $y$. The following table show ranking-click paterns consistent with $\\lambda_{y,x} = 1$:\n",
    "\n",
    "$$\n",
    "\\begin{array}{|c|c|l|}\n",
    "\\hline\\hline\n",
    "xyz & 010 & (1 - \\gamma_{0,1}\\alpha_{x}) \\cdot \\gamma_{0,2}\\alpha_{y} \\cdot (1 - \\gamma_{2,3}\\alpha_{z})\\\\\n",
    "xyz & 011 & (1 - \\gamma_{0,1}\\alpha_{x}) \\cdot \\gamma_{0,2}\\alpha_{y} \\cdot \\gamma_{2,3}\\alpha_{z}\\\\\n",
    "\\hline\n",
    "xzy & 001 & (1 - \\gamma_{0,1}\\alpha_{x}) \\cdot (1 - \\gamma_{0,2}\\alpha_{z}) \\cdot \\gamma_{0,3}\\alpha_{y}\\\\\n",
    "xzy & 011 & (1 - \\gamma_{0,1}\\alpha_{x}) \\cdot \\gamma_{0,2}\\alpha_{z} \\cdot \\gamma_{2,3}\\alpha_{y}\\\\\n",
    "\\hline\n",
    "zxy & 001 & (1 - \\gamma_{0,1}\\alpha_{z}) \\cdot (1 - \\gamma_{0,2}\\alpha_{x}) \\cdot \\gamma_{0,3}\\alpha_{y}\\\\\n",
    "zxy & 101 & \\gamma_{0,1}\\alpha_{z} \\cdot (1 - \\gamma_{1,2}\\alpha_{x}) \\cdot \\gamma_{1,3}\\alpha_{y}\\\\\n",
    "\\hline\\hline\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Cosidering that each ranking (permutation) has the same probability of being shown, we get the following expression for $\\lambda_{y,x}$:\n",
    "\n",
    "\\begin{array}{}\n",
    "P(\\lambda_{y,x} = 1\\vert\\{x,y,z\\}) = &\\gamma_{0,2}\\alpha_{y} - \\gamma_{0,1}\\gamma_{0,2}\\alpha_{x}\\alpha_{y} + \\gamma_{0,3}\\alpha_{y} - \\gamma_{0,2}\\gamma_{0,3}\\alpha_{y}\\alpha_{z} - \\gamma_{0,1}\\gamma_{0,3}\\alpha_{x}\\alpha_{y} + \\\\\n",
    "&\\gamma_{0,1}\\gamma_{0,2}\\gamma_{0,3}\\alpha_{x}\\alpha_{y}\\alpha_{z} + \\gamma_{0,2}\\gamma_{2,3}\\alpha_{y}\\alpha_{z} - \\gamma_{0,1}\\gamma_{0,2}\\gamma_{2,3}\\alpha_{x}\\alpha_{y}\\alpha_{z} + \\gamma_{0,3}\\alpha_{y} - \\gamma_{0,2}\\gamma_{0,3}\\alpha_{x}\\alpha_{y} - \\\\\n",
    "&\\gamma_{0,1}\\gamma_{0,3}\\alpha_{y}\\alpha_{z} + \\gamma_{0,1}\\gamma_{0,2}\\gamma_{0,3}\\alpha_{x}\\alpha_{y}\\alpha_{z} + \\gamma_{0,1}\\gamma_{1,3}\\alpha_{y}\\alpha_{z} - \\gamma_{0,1}\\gamma_{1,2}\\gamma_{1,3}\\alpha_{x}\\alpha_{y}\\alpha_{z}\n",
    "\\end{array}\n",
    "\n",
    "by summing up a few terms in above expression we get\n",
    "\n",
    "\\begin{array}{}\n",
    "P(\\lambda_{y,x} = 1\\vert\\{x,y,z\\}) = &(\\gamma_{0,2} + 2\\gamma_{0,3})\\alpha_{y} - (\\gamma_{0,1}\\gamma_{0,2} + \\gamma_{0,1}\\gamma_{0,3} + \\gamma_{0,2}\\gamma_{0,3})\\alpha_{x}\\alpha_{y} - (\\gamma_{0,1}\\gamma_{0,3} + \\gamma_{0,2}\\gamma_{0,3} - \\gamma_{0,2}\\gamma_{2,3} - \\gamma_{0,1}\\gamma_{1,3})\\alpha_{y}\\alpha_{z} + \\\\\n",
    "&(\\gamma_{0,1}\\gamma_{0,2}\\gamma_{0,3} - \\gamma_{0,1}\\gamma_{0,2}\\gamma_{2,3} + \\gamma_{0,1}\\gamma_{0,2}\\gamma_{0,3} - \\gamma_{0,1}\\gamma_{1,2}\\gamma_{1,3})\\alpha_{x}\\alpha_{y}\\alpha_{z}\n",
    "\\end{array}\n",
    "\n",
    "In more generality we may consider the case in which the rankings are sampled from a non-uniform distribution $P(xyz)$ which denotes the probability of seeing the permutation $xyz$.\n",
    "\n",
    "\\begin{array}{}\n",
    "P(\\lambda_{y,x} = 1\\vert\\{x,y,z\\}) = &\\gamma_{0,2}\\alpha_{y}P(xyz) - \\gamma_{0,1}\\gamma_{0,2}\\alpha_{x}\\alpha_{y}P(xyz) + \\gamma_{0,3}\\alpha_{y}P(xzy) - \\gamma_{0,2}\\gamma_{0,3}\\alpha_{y}\\alpha_{z}P(xzy) - \\gamma_{0,1}\\gamma_{0,3}\\alpha_{x}\\alpha_{y}P(xzy) + \\\\\n",
    "&\\gamma_{0,1}\\gamma_{0,2}\\gamma_{0,3}\\alpha_{x}\\alpha_{y}\\alpha_{z}P(xzy) + \\gamma_{0,2}\\gamma_{2,3}\\alpha_{y}\\alpha_{z}P(xzy) - \\gamma_{0,1}\\gamma_{0,2}\\gamma_{2,3}\\alpha_{x}\\alpha_{y}\\alpha_{z}P(xzy) + \\gamma_{0,3}\\alpha_{y}P(zxy) - \\gamma_{0,2}\\gamma_{0,3}\\alpha_{x}\\alpha_{y}P(zxy) - \\\\\n",
    "&\\gamma_{0,1}\\gamma_{0,3}\\alpha_{y}\\alpha_{z}P(zxy) + \\gamma_{0,1}\\gamma_{0,2}\\gamma_{0,3}\\alpha_{x}\\alpha_{y}\\alpha_{z}P(zxy) + \\gamma_{0,1}\\gamma_{1,3}\\alpha_{y}\\alpha_{z}P(zxy) - \\gamma_{0,1}\\gamma_{1,2}\\gamma_{1,3}\\alpha_{x}\\alpha_{y}\\alpha_{z}P(zxy)\n",
    "\\end{array}\n",
    "\n",
    "summing again a few terms we end up with\n",
    "\n",
    "\\begin{array}{}\n",
    "P(\\lambda_{y,x} = 1\\vert\\{x,y,z\\}) = &(\\gamma_{0,2}P(xyz) + \\gamma_{0,3}(P(xzy) + P(zxy))\\alpha_{y} - (\\gamma_{0,1}\\gamma_{0,2}P(xyz) + \\gamma_{0,1}\\gamma_{0,3}P(xzy) + \\gamma_{0,2}\\gamma_{0,3}P(zxy))\\alpha_{x}\\alpha_{y} - \\\\\n",
    "&((\\gamma_{0,1}\\gamma_{0,3} - \\gamma_{0,1}\\gamma_{1,3})P(zxy) + \\gamma_{0,2}\\gamma_{0,3}P(xzy) - \\gamma_{0,2}\\gamma_{2,3}P(xyz))\\alpha_{y}\\alpha_{z} + \\\\\n",
    "&(\\gamma_{0,1}\\gamma_{0,2}\\gamma_{0,3}P(xzy) - \\gamma_{0,1}\\gamma_{0,2}\\gamma_{2,3}P(xyz) + (\\gamma_{0,1}\\gamma_{0,2}\\gamma_{0,3} - \\gamma_{0,1}\\gamma_{1,2}\\gamma_{1,3})P(zxy))\\alpha_{x}\\alpha_{y}\\alpha_{z}\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Y skipped and X clicked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary random variable $\\lambda_{x,y}$ is 1 only if the document $y$ was presented above document $x$ and the user clicked on document $x$. The following table show ranking-click paterns consistent with $\\lambda_{x,y} = 1$:\n",
    "\n",
    "$$\n",
    "\\begin{array}{|c|c|l|}\n",
    "\\hline\\hline\n",
    "yxz & 010 & (1 - \\gamma_{0,1}\\alpha_{y}) \\cdot \\gamma_{0,2}\\alpha_{x} \\cdot (1 - \\gamma_{2,3}\\alpha_{z})\\\\\n",
    "yxz & 011 & (1 - \\gamma_{0,1}\\alpha_{y}) \\cdot \\gamma_{0,2}\\alpha_{x} \\cdot \\gamma_{2,3}\\alpha_{z}\\\\\n",
    "\\hline\n",
    "yzx & 001 & (1 - \\gamma_{0,1}\\alpha_{y}) \\cdot (1 - \\gamma_{0,2}\\alpha_{z}) \\cdot \\gamma_{0,3}\\alpha_{x}\\\\\n",
    "yzx & 011 & (1 - \\gamma_{0,1}\\alpha_{y}) \\cdot \\gamma_{0,2}\\alpha_{z} \\cdot \\gamma_{2,3}\\alpha_{x}\\\\\n",
    "\\hline\n",
    "zyx & 001 & (1 - \\gamma_{0,1}\\alpha_{z}) \\cdot (1 - \\gamma_{0,2}\\alpha_{y}) \\cdot \\gamma_{0,3}\\alpha_{x}\\\\\n",
    "zyx & 101 & \\gamma_{0,1}\\alpha_{z} \\cdot (1 - \\gamma_{1,2}\\alpha_{y}) \\cdot \\gamma_{1,3}\\alpha_{x}\\\\\n",
    "\\hline\\hline\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Cosidering that each ranking (permutation) has the same probability of being shown, we get the following expression for $\\lambda_{x,y}$:\n",
    "\n",
    "\\begin{array}{}\n",
    "P(\\lambda_{x,y} = 1\\vert\\{x,y,z\\}) = &\\gamma_{0,2}\\alpha_{x} - \\gamma_{0,1}\\gamma_{0,2}\\alpha_{x}\\alpha_{y} + \\gamma_{0,3}\\alpha_{x} - \\gamma_{0,2}\\gamma_{0,3}\\alpha_{x}\\alpha_{z} - \\gamma_{0,1}\\gamma_{0,3}\\alpha_{y}\\alpha_{x} + \\\\\n",
    "&\\gamma_{0,1}\\gamma_{0,2}\\gamma_{0,3}\\alpha_{x}\\alpha_{y}\\alpha_{z} + \\gamma_{0,2}\\gamma_{2,3}\\alpha_{x}\\alpha_{z} - \\gamma_{0,1}\\gamma_{0,2}\\gamma_{2,3}\\alpha_{x}\\alpha_{y}\\alpha_{z} + \\gamma_{0,3}\\alpha_{x} - \\gamma_{0,2}\\gamma_{0,3}\\alpha_{x}\\alpha_{y} - \\\\\n",
    "&\\gamma_{0,1}\\gamma_{0,3}\\alpha_{x}\\alpha_{z} + \\gamma_{0,1}\\gamma_{0,2}\\gamma_{0,3}\\alpha_{x}\\alpha_{y}\\alpha_{z} + \\gamma_{0,1}\\gamma_{1,3}\\alpha_{x}\\alpha_{z} - \\gamma_{0,1}\\gamma_{1,2}\\gamma_{1,3}\\alpha_{x}\\alpha_{y}\\alpha_{z} \n",
    "\\end{array}\n",
    "\n",
    "by summing up a few terms in above expression we get\n",
    "\n",
    "\\begin{array}{}\n",
    "P(\\lambda_{x,y} = 1\\vert\\{x,y,z\\}) = &(\\gamma_{0,2} + 2\\gamma_{0,3})\\alpha_{x} - (\\gamma_{0,1}\\gamma_{0,2} + \\gamma_{0,1}\\gamma_{0,3} + \\gamma_{0,2}\\gamma_{0,3})\\alpha_{x}\\alpha_{y} - (\\gamma_{0,1}\\gamma_{0,3} + \\gamma_{0,2}\\gamma_{0,3} - \\gamma_{0,2}\\gamma_{2,3} - \\gamma_{0,1}\\gamma_{1,3})\\alpha_{x}\\alpha_{z} + \\\\\n",
    "&(\\gamma_{0,1}\\gamma_{0,2}\\gamma_{0,3} - \\gamma_{0,1}\\gamma_{0,2}\\gamma_{2,3} + \\gamma_{0,1}\\gamma_{0,2}\\gamma_{0,3} - \\gamma_{0,1}\\gamma_{1,2}\\gamma_{1,3})\\alpha_{x}\\alpha_{y}\\alpha_{z}\n",
    "\\end{array}\n",
    "\n",
    "In more generality we may consider the case in which the rankings are sampled from a non-uniform distribution $P(xyz)$ which denotes the probability of seeing the permutation $xyz$.\n",
    "\n",
    "\\begin{array}{}\n",
    "P(\\lambda_{x,y} = 1\\vert\\{x,y,z\\}) = &\\gamma_{0,2}\\alpha_{x}P(yxz) - \\gamma_{0,1}\\gamma_{0,2}\\alpha_{x}\\alpha_{y}P(yxz) + \\gamma_{0,3}\\alpha_{x}P(yzx) - \\gamma_{0,2}\\gamma_{0,3}\\alpha_{x}\\alpha_{z}P(yzx) - \\gamma_{0,1}\\gamma_{0,3}\\alpha_{x}\\alpha_{y}P(yzx) + \\\\\n",
    "&\\gamma_{0,1}\\gamma_{0,2}\\gamma_{0,3}\\alpha_{x}\\alpha_{y}\\alpha_{z}P(yzx) + \\gamma_{0,2}\\gamma_{2,3}\\alpha_{x}\\alpha_{z}P(yzx) - \\gamma_{0,1}\\gamma_{0,2}\\gamma_{2,3}\\alpha_{x}\\alpha_{y}\\alpha_{z}P(yzx) + \\gamma_{0,3}\\alpha_{x}P(zyx) - \\gamma_{0,2}\\gamma_{0,3}\\alpha_{x}\\alpha_{y}P(zyx) - \\\\\n",
    "&\\gamma_{0,1}\\gamma_{0,3}\\alpha_{x}\\alpha_{z}P(zyx) + \\gamma_{0,1}\\gamma_{0,2}\\gamma_{0,3}\\alpha_{x}\\alpha_{y}\\alpha_{z}P(zyx) + \\gamma_{0,1}\\gamma_{1,3}\\alpha_{x}\\alpha_{z}P(zyx) - \\gamma_{0,1}\\gamma_{1,2}\\gamma_{1,3}\\alpha_{x}\\alpha_{y}\\alpha_{z}P(zyx)\n",
    "\\end{array}\n",
    "\n",
    "summing again a few terms we end up with\n",
    "\n",
    "\\begin{array}{}\n",
    "P(\\lambda_{x,y} = 1\\vert\\{x,y,z\\}) = &(\\gamma_{0,2}P(yxz) + \\gamma_{0,3}(P(yzx) + P(zyx))\\alpha_{x} - (\\gamma_{0,1}\\gamma_{0,2}P(yxz) + \\gamma_{0,1}\\gamma_{0,3}P(yzx) + \\gamma_{0,2}\\gamma_{0,3}P(zyx))\\alpha_{x}\\alpha_{y} - \\\\\n",
    "&((\\gamma_{0,1}\\gamma_{0,3} - \\gamma_{0,1}\\gamma_{1,3})P(zyx) + \\gamma_{0,2}\\gamma_{0,3}P(yzx) - \\gamma_{0,2}\\gamma_{2,3}P(yxz))\\alpha_{x}\\alpha_{z} + \\\\\n",
    "&(\\gamma_{0,1}\\gamma_{0,2}\\gamma_{0,3}P(yzx) - \\gamma_{0,1}\\gamma_{0,2}\\gamma_{2,3}P(yxz) + (\\gamma_{0,1}\\gamma_{0,2}\\gamma_{0,3} - \\gamma_{0,1}\\gamma_{1,2}\\gamma_{1,3})P(zyx))\\alpha_{x}\\alpha_{y}\\alpha_{z}\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formula for Differences of Lambdas\n",
    "\n",
    "Considering a fixed triplet of documents \\{x, y, z\\}, than the difference in $\\lambda$s for pair $(x, y)$ is\n",
    "\n",
    "$$\n",
    "P(\\lambda_{x,y} = 1\\vert\\{x,y,z\\}) - P(\\lambda_{y,x} = 1\\vert\\{x,y,z\\}) = \\left[\\gamma_{0,2} + 2\\gamma_{0,3} - \\alpha_{z}(\\gamma_{0,1}\\gamma_{0,3} + \\gamma_{0,2}\\gamma_{0,3} - \\gamma_{0,2}\\gamma_{2,3} - \\gamma_{0,1}\\gamma_{1,3})\\right](\\alpha_{x} - \\alpha_{y})\n",
    "$$\n",
    "\n",
    "which leads to the following definition of $\\Lambda_{x,y}$\n",
    "\n",
    "\\begin{align}\n",
    "\\Lambda_{x,y} &= \\sum_{z\\in D\\setminus{\\{x,y}\\}}\\frac{\\left(P(\\lambda_{x,y} = 1\\vert\\{x,y,z\\}) - P(\\lambda_{y,x} = 1\\vert\\{x,y,z\\})\\right)}{\\vert D\\vert\\choose3}\\\\\n",
    "&= \\frac{\\left[\\gamma_{0,2} + 2\\gamma_{0,3} - \\left(\\sum_{d\\in D\\setminus{\\{x,y}\\}}\\alpha_{d}\\right)(\\gamma_{0,1}\\gamma_{0,3} + \\gamma_{0,2}\\gamma_{0,3} - \\gamma_{0,2}\\gamma_{2,3} - \\gamma_{0,1}\\gamma_{1,3})\\right](\\alpha_{x} - \\alpha_{y})}{\\vert D\\vert\\choose3}\\\\\n",
    "\\end{align}\n",
    "\n",
    "**<font color='red'>BEWARE:</font>** The above result holds only for rankings sampled uniformly at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "import contextlib\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def printoptions(*args, **kwargs):\n",
    "    original = np.get_printoptions()\n",
    "    np.set_printoptions(*args, **kwargs)\n",
    "    yield \n",
    "    np.set_printoptions(**original)\n",
    "\n",
    "with open('./data/model_query_uniform_lambdas_v2_collection_c3.pkl') as ifile:\n",
    "    MQD = pickle.load(ifile)\n",
    "\n",
    "alphas = MQD['UBM']['2548']['model'].p_attraction\n",
    "gammas = MQD['UBM']['2548']['model'].p_examination\n",
    "deltas = MQD['UBM']['2548']['relevances']\n",
    "deltas = deltas[:, None] - deltas[None, :]\n",
    "viewed_lambdas = MQD['UBM']['2548']['stats'][1000000]['viewed_lambdas'][0]\n",
    "total_lambdas = MQD['UBM']['2548']['stats'][1000000]['total_lambdas'][0]\n",
    "\n",
    "def Lambda(i, j, alphas, gammas):\n",
    "    alphas_sum = alphas.sum() - alphas[i] - alphas[j]\n",
    "    return (gammas[1, -1] + 2 * gammas[2, -1] - alphas_sum * \n",
    "            (gammas[0, -1] * gammas[2, -1] + \n",
    "             gammas[1, -1] * gammas[2, -1] - \n",
    "             gammas[1, -1] * gammas[2, 1] -\n",
    "             gammas[0, -1] * gammas[2, 0])) * (alphas[i] - alphas[j]) / 120.\n",
    "\n",
    "true_lambdas = np.array([[Lambda(i, j, alphas, gammas) for j in range(10)] for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with printoptions(precision=4, linewidth=np.inf):\n",
    "    print alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with printoptions(precision=4, linewidth=np.inf):\n",
    "    print gammas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with printoptions(precision=4, linewidth=np.inf):\n",
    "    print deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with printoptions(precision=4, linewidth=np.inf):\n",
    "    print np.nan_to_num(viewed_lambdas / deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with printoptions(precision=4, linewidth=np.inf):\n",
    "    print np.nan_to_num(total_lambdas / deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with printoptions(precision=4, linewidth=np.inf):\n",
    "    print np.nan_to_num(true_lambdas / deltas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
